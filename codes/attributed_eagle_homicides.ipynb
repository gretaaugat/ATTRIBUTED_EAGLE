{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homicidios\n",
    "### Source: https://www.ipea.gov.br/atlasviolencia/filtros-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dtaidistance.dtw import distance_matrix, distance\n",
    "from scipy.spatial.distance import euclidean\n",
    "from fastdtw import fastdtw\n",
    "import picos as pic\n",
    "import itertools as it\n",
    "import copy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#N = number of neighbors - 1 up to 20\n",
    "#feature = path of feature file\n",
    "#N=5\n",
    "#feature = pd.read_csv(\"data/IBGE/census_2010/RS/aggregated_by_weighting_area/joined/Renda.csv\",index_col=0)\n",
    "def graph_feat(N,feature,feature_col,file_matrix,file_hom):\n",
    "    # constrói um grafo knn \n",
    "\n",
    "    adj = pd.read_csv(file_matrix,index_col=0)\n",
    "    adj.index = adj.index.map(str)\n",
    "    \n",
    "    def build_graph(adj,nn_radi):\n",
    "        names = adj.index\n",
    "        G = nx.Graph()\n",
    "        tmp = np.array(adj)\n",
    "        tmp = np.argsort(tmp)\n",
    "        tmp = np.argwhere(tmp < nn_radi)\n",
    "        for e in tmp:\n",
    "            #if para testar se e[0]electionwhowon != e[1]electionwhowon\n",
    "            G.add_edge(names[e[0]],names[e[1]])\n",
    "        return(G)\n",
    "\n",
    "    # grafos de 1 até N vizinhos\n",
    "\n",
    "    G = [build_graph(adj,i) for i in range(1,N)]\n",
    "    \n",
    "    feature.index = feature.index.map(str)\n",
    "    #print(feature.index)\n",
    "    #print(\"feature.columns\",feature.columns)\n",
    "\n",
    "    for gg in G:\n",
    "        attrs={}\n",
    "\n",
    "        for edge in gg.edges():\n",
    "            attrs[(edge[0],edge[1])] = {}\n",
    "\n",
    "            for v in feature.columns[feature_col:]:\n",
    "\n",
    "                #se quiser trocar np.abs para calcular a diferença\n",
    "                #w = np.abs(feature[v][edge[0]] - feature[v][edge[1]]) \n",
    "                w = np.mean([feature[v][edge[0]] , feature[v][edge[1]]])       \n",
    "\n",
    "                attrs[(edge[0],edge[1])][v] = w\n",
    "        \n",
    "        nx.set_edge_attributes(gg, attrs)\n",
    "    \n",
    "    hom = pd.read_csv(file_hom,index_col=0)\n",
    "    hom.index = hom.index.map(str)\n",
    "    \n",
    "    for gg in G:\n",
    "        attrs={}\n",
    "\n",
    "        for edge in gg.edges():\n",
    "            try:\n",
    "                b0 = hom['homicidios'][edge[0]]\n",
    "                b1 = hom['homicidios'][edge[1]]\n",
    "\n",
    "                attrs[(edge[0],edge[1])] = {'hom' : np.mean([b0,b1])}\n",
    "                #attrs[(edge[0],edge[1])] = {'hom' : np.abs([b0-b1])}\n",
    "                                            \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        nx.set_edge_attributes(gg, attrs)\n",
    "    \n",
    "    ### I.Preprocessing Phase: Computations over the Domain\n",
    "\n",
    "    K = len(G)\n",
    "\n",
    "    #Amount of features\n",
    "    F= len(feature.columns[feature_col:])\n",
    "\n",
    "    def feat_edge(D,x):\n",
    "        data_2 = [v for _,_,v in D.edges.data(x)]\n",
    "        data_2_at = [v for v in data_2 if v is not None]\n",
    "        d2 = np.histogram(data_2_at,bins=5)[0]\n",
    "        #fixed the number of bins, not using scott anymore\n",
    "        #d2 = np.histogram(data_2_at,bins=5)[0]\n",
    "        return(d2/float(sum(d2)))\n",
    "\n",
    "    ### Step 1: Feature Representation Model\n",
    "\n",
    "\n",
    "    #for i in range(K):\n",
    "        #PDF computed for edges\n",
    "        #PDF_e[i] = feat_edge((D[i]),'num_critic_for_reviews'),feat_edge((D[i]),'duration'),feat_edge((D[i]),'director_facebook_likes'), feat_edge((D[i]),'actor_3_facebook_likes'), feat_edge((D[i]),'actor_1_facebook_likes'),feat_edge((D[i]),'gross'),feat_edge((D[i]),'num_voted_users'),feat_edge((D[i]),'cast_total_facebook_likes'),feat_edge((D[i]),'facenumber_in_poster'), feat_edge((D[i]),'num_user_for_reviews'), feat_edge((D[i]),'budget'), feat_edge((D[i]),'title_year'),feat_edge((D[i]),'actor_2_facebook_likes'),feat_edge((D[i]),'movie_facebook_likes')\n",
    "\n",
    "    PDF_e = [[feat_edge(gg,v) for v in feature.columns[feature_col:]] for gg in G]\n",
    "\n",
    "    #for i in range(K): \n",
    "    #    PDF_e.append([])\n",
    "    #    for j,v in enumerate(alfabetizacao.columns[2:]):\n",
    "    #        PDF_e[i].append(feat_edge(G[i],v)) \n",
    "    \n",
    "    ### Step 2: Feature Diversity Model\n",
    "\n",
    "    dists_e = [distance_matrix(PDF_e[i]) for i in range(K)]\n",
    "    \n",
    "    #edge\n",
    "    SF_e = np.nan_to_num(np.mean(dists_e,axis=0),posinf=0)\n",
    "    \n",
    "    \n",
    "    ### II. Query Phase: Summary Creation\n",
    "\n",
    "    ### Step 1: Domain-specificity Model\n",
    "    PDF_ge = [feat_edge(gg,'hom') for gg in G]\n",
    "    \n",
    "    \n",
    "    diff_e = [[distance(PDF_ge[i],PDF_e[i][l]) for l in range(F)] for i in range(K)]\n",
    "\n",
    "    h_e= np.mean(diff_e,axis=0)\n",
    "                                                                                 \n",
    "    ### Step 2: Feature Selection\n",
    "\n",
    "    #Regularization Parameters l1,l2, l3\n",
    "\n",
    "    l1 = 1/F\n",
    "    l2 = 1\n",
    "    l3 = 1\n",
    "\n",
    "    #Matriz identidade: np.identity(F)\n",
    "\n",
    "    Q_e = np.multiply(SF_e,l1) + np.multiply(np.identity(F),l2)\n",
    "    r_e = np.multiply(h_e,l3)\n",
    "\n",
    "    sel_feat = 3\n",
    "\n",
    "    #Solver Edge\n",
    "    prob_e = pic.Problem()\n",
    "    K=F\n",
    "    #f = pic.IntegerVariable('f',K)\n",
    "\n",
    "    f = pic.RealVariable('f',K)\n",
    "    prob_e.add_constraint(pic.sum(f.T)<=F)\n",
    "    #prob_e.add_constraint(pic.sum(f.T)<F)\n",
    "    prob_e.add_constraint(pic.sum(f.T)>=sel_feat)\n",
    "    #Q_e = pic.new_param('Q',Q_e)\n",
    "    #r_e = pic.new_param('r',r_e)\n",
    "    prob_e.set_objective('min',f.T*Q_e*f+f.T*r_e)\n",
    "    sol_e = prob_e.solve(solver=\"ecos\",primals=None,duals=None,max_footprints=100,verbosity=0,rel_prim_fsb_tol=1e-3,rel_dual_fsb_tol=1e-3,abs_prim_fsb_tol=1e-3,abs_dual_fsb_tol=1e-3)\n",
    "\n",
    "    values = np.array(list(sol_e.primals.values())[0])\n",
    "    \n",
    "    #order = np.argsort(-v)\n",
    "    order = np.argsort(-values)\n",
    "\n",
    "    result_order = list(zip(feature.columns[feature_col:][order],values[order]))\n",
    "    \n",
    "    features_order = list(feature.columns[feature_col:][order])\n",
    "    \n",
    "    y = np.round(list(sol_e.primals.values()))\n",
    "    result = np.where(y == 1)\n",
    "    \n",
    "    \n",
    "    return(features_order,result_order, result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greta/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Numero de vizinhos\n",
    "N=2\n",
    "#Coluna com o Codigo do municipio (as features são consideradas a partir desta coluna)\n",
    "feature_col = 20\n",
    "feature = pd.read_csv(\"data/Brasil_new/data_noelections.csv\", index_col=feature_col)\n",
    "features_order,result_order, result = graph_feat(N,feature,feature_col,\"data/Brasil_new/filtered_adjacency_matrix_inv.csv\",\"data/homicidios/homicidios_2010_abs.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict({ 'Ordem' : result_order\n",
    "                  }, orient='index').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ordem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>(CENSUS_PessoaRenda_V121, 0.31601626924161696)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>(CENSUS_PessoaRenda_V055, 0.31592997128330463)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>(CENSUS_PessoaRenda_V077, 0.3159106132008879)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>(CENSUS_PessoaRenda_V011, 0.3159104890451584)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>(CENSUS_ResponsavelRenda_V121, 0.3155686906821...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>(CENSUS_ResponsavelRenda_V055, 0.3155685760037...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>(CENSUS_Pessoa09_V188, 0.31556181671711475)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>(CENSUS_Domicilio01_V181, 0.31549469758082144)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>(CENSUS_ResponsavelRenda_V100, 0.315478894215076)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>(CENSUS_ResponsavelRenda_V034, 0.3154787794944...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Ordem\n",
       "0     (CENSUS_PessoaRenda_V121, 0.31601626924161696)\n",
       "1     (CENSUS_PessoaRenda_V055, 0.31592997128330463)\n",
       "2      (CENSUS_PessoaRenda_V077, 0.3159106132008879)\n",
       "3      (CENSUS_PessoaRenda_V011, 0.3159104890451584)\n",
       "4  (CENSUS_ResponsavelRenda_V121, 0.3155686906821...\n",
       "5  (CENSUS_ResponsavelRenda_V055, 0.3155685760037...\n",
       "6        (CENSUS_Pessoa09_V188, 0.31556181671711475)\n",
       "7     (CENSUS_Domicilio01_V181, 0.31549469758082144)\n",
       "8  (CENSUS_ResponsavelRenda_V100, 0.315478894215076)\n",
       "9  (CENSUS_ResponsavelRenda_V034, 0.3154787794944..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'selected_features': ['CENSUS_PessoaRenda_V121',\n",
       "  'CENSUS_PessoaRenda_V055',\n",
       "  'CENSUS_PessoaRenda_V077',\n",
       "  'CENSUS_PessoaRenda_V011',\n",
       "  'CENSUS_ResponsavelRenda_V121',\n",
       "  'CENSUS_ResponsavelRenda_V055',\n",
       "  'CENSUS_Pessoa09_V188',\n",
       "  'CENSUS_Domicilio01_V181',\n",
       "  'CENSUS_ResponsavelRenda_V100',\n",
       "  'CENSUS_ResponsavelRenda_V034',\n",
       "  'CENSUS_ResponsavelRenda_V077',\n",
       "  'CENSUS_ResponsavelRenda_V011',\n",
       "  'CENSUS_Entorno05_V1042',\n",
       "  'CENSUS_Domicilio02_V036',\n",
       "  'CENSUS_PessoaRenda_V100',\n",
       "  'CENSUS_PessoaRenda_V034',\n",
       "  'CENSUS_Entorno05_V1022',\n",
       "  'CENSUS_Domicilio01_V173']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#features_order[1:157]\n",
    "\n",
    "#data_json = {'selected_features':features_order[1:11]}\n",
    "\n",
    "data_json = {'selected_features':features_order[0:18]}\n",
    "\n",
    "data_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def escrever_json(lista):\n",
    "    with open('resultados/hom_abs_n2_18_avg.json', 'w') as f:\n",
    "        json.dump(lista, f, indent=4)\n",
    "    \n",
    "escrever_json(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json_full = {'selected_features':features_order[0:]}\n",
    "\n",
    "def escrever_json_full(lista):\n",
    "    with open('resultados_full/GRAPH_ELECTIONS_CENSUS_ALL1.json', 'w') as f:\n",
    "        json.dump(lista, f, indent=4)\n",
    "    \n",
    "escrever_json_full(data_json_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
